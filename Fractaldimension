import pandas as pd
import numpy as np
from scipy.spatial.distance import pdist
from datetime import timedelta

# Sample data (replace with actual)
data = {
    'partyid': ['A', 'A', 'A', 'B', 'B', 'C', 'C', 'C'],
    'transferdate': pd.to_datetime(['2025-04-01', '2025-04-10', '2025-05-01',
                                    '2025-04-02', '2025-04-05', '2025-04-01',
                                    '2025-04-03', '2025-05-01']),
    'transferamount': [1000, 1050, 30000, 500, 600, 200, 250, 8000],
    'bankname': ['X', 'X', 'Y', 'Z', 'Z', 'X', 'X', 'Y'],
    'creditlimit': [10000, 10000, 10000, 5000, 5000, 2000, 2000, 2000]
}
df = pd.DataFrame(data)

# Parameters
LOOKBACK_DAYS = 30
RISK_THRESHOLD = 0.995  # Top 0.5% risky parties

# Step 1: Filter per-party recent transactions
def filter_recent_per_party(df, lookback_days):
    result = []
    for partyid, group in df.groupby('partyid'):
        max_date = group['transferdate'].max()
        cutoff = max_date - timedelta(days=lookback_days)
        result.append(group[group['transferdate'] >= cutoff])
    return pd.concat(result)

df_recent = filter_recent_per_party(df, LOOKBACK_DAYS)

# Step 2: Build risk signals including fractal dimension
def build_fraud_signals(df):
    party_signals = []

    for partyid, group in df.groupby('partyid'):
        group = group.sort_values(by='transferdate')

        # Fractal dimension on transfer amount
        values = group['transferamount'].values.reshape(-1, 1)
        if len(values) >= 2:
            distances = pdist(values, metric='euclidean')
            if np.all(distances == 0):
                fractal_dim = 0.0
            else:
                epsilons = np.linspace(1, np.max(distances), num=10)
                box_counts = [np.sum(distances >= eps) for eps in epsilons]
                logs = [(np.log(1/eps), np.log(N)) for eps, N in zip(epsilons, box_counts) if N > 0]
                if len(logs) >= 2:
                    x, y = zip(*logs)
                    fractal_dim = np.polyfit(x, y, 1)[0]
                else:
                    fractal_dim = 0.0
        else:
            fractal_dim = 0.0

        # Time gap variability
        dates = group['transferdate']
        if len(dates) >= 2:
            time_gaps = (dates - dates.shift(1)).dt.days.dropna()
            gap_std = time_gaps.std()
        else:
            gap_std = 0

        # Bank diversity
        bank_diversity = group['bankname'].nunique()

        # Combined score
        score = fractal_dim + 0.1 * gap_std + 0.2 * bank_diversity

        party_signals.append({
            'partyid': partyid,
            'fractal_dim': fractal_dim,
            'gap_std': gap_std,
            'bank_diversity': bank_diversity,
            'risk_score': score,
            'last_txn_date': group['transferdate'].max()
        })

    return pd.DataFrame(party_signals)

party_signals = build_fraud_signals(df_recent)

# Step 3: Risk flag based on top X% scores
party_signals['risk_percentile'] = party_signals['risk_score'].rank(pct=True)
party_signals['risk_flag'] = (party_signals['risk_percentile'] >= RISK_THRESHOLD).astype(int)

# Step 4: Merge back and calculate active flag
df = df.merge(party_signals, on='partyid', how='left')
df['days_since_last_txn'] = (df['transferdate'].max() - df['last_txn_date']).dt.days
df['active_flag'] = ((df['risk_flag'] == 1) & (df['days_since_last_txn'] <= LOOKBACK_DAYS)).astype(int)

# Final result
print(df[['partyid', 'transferdate', 'transferamount', 'risk_score', 'risk_flag', 'active_flag']])

import pandas as pd
import numpy as np
from scipy.spatial.distance import pdist
from datetime import timedelta

# Sample ACH data (replace with your actual data)
data = {
    'partyid': ['A', 'A', 'A', 'B', 'B', 'C', 'C', 'C'],
    'transferdate': pd.to_datetime(['2025-04-01', '2025-04-10', '2025-05-01',
                                    '2025-04-02', '2025-04-05', '2025-04-01',
                                    '2025-04-03', '2025-05-01']),
    'transferamount': [1000, 1050, 30000, 500, 600, 200, 250, 8000],
    'bankname': ['X', 'X', 'Y', 'Z', 'Z', 'X', 'X', 'Y'],
    'creditlimit': [10000, 10000, 10000, 5000, 5000, 2000, 2000, 2000]
}
df = pd.DataFrame(data)

# Parameters
LOOKBACK_DAYS = 30
RISK_THRESHOLD = 0.995  # Top 0.5% parties flagged

# Step 1: Filter for recent transactions
cutoff_date = df['transferdate'].max() - timedelta(days=LOOKBACK_DAYS)
df_recent = df[df['transferdate'] >= cutoff_date]

# Step 2: Fractal-based risk scoring per partyid
def build_fraud_signals(df):
    party_signals = []

    for partyid, group in df.groupby('partyid'):
        group = group.sort_values(by='transferdate')

        # Signal 1: Fractal Dimension of transfer amounts
        values = group['transferamount'].values.reshape(-1, 1)
        if len(values) >= 2:
            distances = pdist(values, metric='euclidean')
            if np.all(distances == 0):
                fractal_dim = 0.0
            else:
                epsilons = np.linspace(1, np.max(distances), num=10)
                box_counts = [np.sum(distances >= eps) for eps in epsilons]
                logs = [(np.log(1/eps), np.log(N)) for eps, N in zip(epsilons, box_counts) if N > 0]
                if len(logs) >= 2:
                    x, y = zip(*logs)
                    fractal_dim = np.polyfit(x, y, 1)[0]
                else:
                    fractal_dim = 0.0
        else:
            fractal_dim = 0.0

        # Signal 2: Std Dev of time gaps
        dates = group['transferdate'].sort_values()
        if len(dates) >= 2:
            time_gaps = (dates - dates.shift(1)).dt.days.dropna()
            gap_std = time_gaps.std()
        else:
            gap_std = 0

        # Signal 3: Bank diversity
        bank_diversity = group['bankname'].nunique()

        # Combined risk score
        score = fractal_dim + 0.1 * gap_std + 0.2 * bank_diversity

        party_signals.append({
            'partyid': partyid,
            'fractal_dim': fractal_dim,
            'gap_std': gap_std,
            'bank_diversity': bank_diversity,
            'risk_score': score,
            'last_risky_date': group['transferdate'].max()
        })

    return pd.DataFrame(party_signals)

party_signals = build_fraud_signals(df_recent)

# Step 3: Risk ranking
party_signals['risk_percentile'] = party_signals['risk_score'].rank(pct=True)
party_signals['risk_flag'] = (party_signals['risk_percentile'] >= RISK_THRESHOLD).astype(int)

# Step 4: Merge signals with full dataset
df = df.merge(party_signals, on='partyid', how='left')
df['days_since_last_risk'] = (df['transferdate'].max() - df['last_risky_date']).dt.days
df['active_flag'] = ((df['days_since_last_risk'] <= LOOKBACK_DAYS) & (df['risk_flag'] == 1)).astype(int)

# Final output
print(df[['partyid', 'transferdate', 'transferamount', 'risk_score', 'risk_flag', 'active_flag']])
